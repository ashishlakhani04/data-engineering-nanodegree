Kafka Architecture

Kafka servers are referred to as brokers
All of the brokers that work together are referred to as a cluster
Clusters may consist of just one broker, or thousands of brokers
Apache Zookeeper is used by Kafka brokers to determine which broker is the leader of a given partition and topic
Zookeeper keeps track of which brokers are part of the Kafka cluster
Zookeeper stores configuration for topics and permissions (Access Control Lists - ACLs)
	ACLs are Permissions associated with an object. In Kafka, this typically refers to a user’s permissions with respect to production and consumption, and/or the topics themselves.
Kafka nodes may gracefully join and leave the cluster
Kafka runs on the Java Virtual Machine (JVM)


Kafka Clustering - Key Points

Kafka servers are referred to as brokers and organized into clusters.
Kafka uses Apache Zookeeper to keep track of topic and ACL configuration, as well as determine leadership and cluster management.
Usage of ZooKeeper means that Kafka brokers can typically seamlessly join and leave clusters, allowing Kafka to grow easily as its usage increases or decreases.



The way that Kafka stores data is pretty simple. It has a data directory on a disk where it stores logs of data and text files. /var/lib/kafka/data is a directory where Kafta sorts data in your workspace and in many Kafka productions systems.

Each topic receives its own sub-directory with the associated name of the topic.
Kafka may store more than one log file for a given topic



Preventing Data Loss


Based on an understanding that machines can fail, one of the core features of Kafka is the concept of replication.

Replication – when the data is written to many brokers
Leader Broker – the broker responsible for sending and receiving data to clients for a given topic partition
Replicas – any brokers that are storing replicated data
If the leader broker were to fail, one of the replicas would be elected the new topic partition leader by a zookeeper election.

The exact number of replicas used can be configured globally as a Kafta server configuration item or set individually on every topic you create. But keep a few things in mind:

You can not have more replicas than brokers
Data replication has overhead
Always enable replication in a production cluster to prevent data loss



Repartition the topic

Now that you've seen what a topic with a single partition looks like, let's see what happens if we modify the number of partitions

kafka-topics --alter --topic kafka-arch --partitions 3 --zookeeper localhost:2181




https://www.cloudkarafka.com/blog/cloudkarafka-what-is-zookeeper.html
https://kafka.apache.org/documentation/#design
https://www.confluent.io/blog/secure-kafka-deployment-best-practices/



Configuring Kafka Topics

To recap a few key points:

Kafka uses data replication to duplicate data across multiple machines to prevent data loss in case a broker fails
Commonlym the desired replication factor is set at the topic level and the value should always be specificed when creating a topic
If a leader broker fails or is removed from a cluster, a replica broker will be become the new leader
To become a new leader, the broker must be an In-Sync Replica (ISR)
Configuration in Kafka includes configured the desired number of ISRs
If the number of ISRs is too large this can slow down processing


https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/


Partitioning Topics Tips and Equation


The “right” number of partitions is highly dependent on the scenario.
The most important number to understand is desired throughput. How many MB/s do you need to achieve to hit your goal?
You can easily add partitions at a later date by modifying a topic.
Partitions have performance consequences. They require additional networking latency and potential rebalances, leading to unavailability.
Determine the number of partitions you need by dividing the overall throughput you want by the throughput per single consumer partition or the throughput per single producer partition. Pick the larger of these two numbers to determine the needed number of partitions.
# Partitions = Max(Overall Throughput/Producer Throughput, Overall Throughput/Consumer Throughput)
Example from video, with 3 Producers and 5 Consumers, each operating at 10MB/s per single producer/consumer partition: Max(100MBs/(3 * 10MB/s), 100MBs/(5 * 10MB/s)) = Max(2) ~= *4 partitions needed*



